{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuKDZBBHRoEP1Rt+n+yA7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekqlsrla/TextBook/blob/main/HandsOn_MachineLearning/Chapter07_%EC%95%99%EC%83%81%EB%B8%94_%ED%95%99%EC%8A%B5%EA%B3%BC_%EB%9E%9C%EB%8D%A4_%ED%8F%AC%EB%A0%88%EC%8A%A4%ED%8A%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Chapter 07 앙상블 학습과 랜덤 포레스트**\n",
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "9SOQDi239RyV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.1 투표 기반 분류\n",
        "\n",
        "1. 직접 투표 분류기 : 다수결 투표로 정해지는 분류"
      ],
      "metadata": {
        "id": "LmAXCFwZ9ZHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷런의 투표 기반 분류기를 만들고 훈련시키는 코드\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "\n",
        "log_clf = LogisticRegression()\n",
        "rnd_clf = RandomForestClassifier()\n",
        "svm_clf = SVC()\n",
        "\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators = [('lr', log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
        "    voting = 'hard'\n",
        ")\n",
        "\n",
        "voting_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "Qw0chlnHO2ln",
        "outputId": "1f65b131-9fe9-4a8c-937e-f9285a5bc4cd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lr', LogisticRegression()),\n",
              "                             ('rf', RandomForestClassifier()), ('svc', SVC())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;lr&#x27;, LogisticRegression()),\n",
              "                             (&#x27;rf&#x27;, RandomForestClassifier()), (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>lr</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svc</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf) :\n",
        "  clf.fit(X_train,y_train)\n",
        "  y_pred = clf.predict(X_test)\n",
        "  print(clf.__class__.__name__, accuracy_score(y_test,y_pred))\n",
        "\n",
        "#투표 기반 분류기가 다른 개별 분류기보다 성능이 조금 더 높은 것을 확인할 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk35u2AVPTqe",
        "outputId": "32f10fd6-f88d-4d97-dcad-90c2a0cea839"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.896\n",
            "SVC 0.896\n",
            "VotingClassifier 0.896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모든 분류기가 클래스의 확률을 예측할 수 있으면, 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스를 예측할 수 있음 **= 간접투표**\n",
        "* `voting = \"soft\"`로 바꾸고, 모든 분류기가 클래스의 확률을 추정할 수 있으면\n",
        "됨"
      ],
      "metadata": {
        "id": "z3vLkOW6RHHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7.2 배깅과 페이스팅\n",
        "\n",
        "1. **배깅** | 훈련 세트에서 중복을 허용하여 샘플링하는 방식\n",
        "\n",
        "2. **페이스팅** | 중복을 허용하지 않고 샘플링 하는 방식\n",
        "\n",
        "* 모든 예측기가 훈련을 마치면 앙상블은 모든 예측기의 예측을 모아서 새로운 샘플에 대한 예측을 만듦. 수집함수는 전형적으로 분류일 때는 **통계적 최빈값**이고 회귀에 대해서는 **평균**을 계산함"
      ],
      "metadata": {
        "id": "Djlf3_zMRs1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 사이킷런의 배깅과 페이스팅\n",
        "\n",
        "* `bootstrap= False`로 지정하면 페이스팅을 사용할 수 있음"
      ],
      "metadata": {
        "id": "_lJHJHs0WquE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators = 500,\n",
        "    max_samples = 100, bootstrap = True, n_jobs = -1\n",
        ")\n",
        "\n",
        "bag_clf.fit(X_train,y_train)\n",
        "y_pred = bag_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "ieFumnD4W9qP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) oob 평가\n",
        "\n",
        "* 배깅을 사용하면 어떤 샘플은 한 예측기를 위해 여러 번 샘플링되고 어떤 것은 전혀 선택되지 않을 수 있음. 예측기가 훈련되는 동안에는 oob 샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob 샘플을 사용해 평가할 수 있음"
      ],
      "metadata": {
        "id": "4uWampBDX3YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(), n_estimators = 500,\n",
        "    bootstrap = True, n_jobs = -1, oob_score = True\n",
        ")\n",
        "\n",
        "bag_clf.fit(X_train,y_train)\n",
        "bag_clf.oob_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bURUWrGbYKqE",
        "outputId": "32e9f65b-fb9d-48af-e3d4-5a855387ec72"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8986666666666666"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4yc859sYl6r",
        "outputId": "40ded19f-fb60-46ab-d913-8685f286abaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.904"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 결정 함수의 값 : 결정함수는 각 훈련 샘플의 클래스 확률을 반환\n",
        "  * 다음 예를 보면 oob 평가는 첫 번째 훈련 샘플이 양성 클래스에 속할 확률을 65%로 추정"
      ],
      "metadata": {
        "id": "USsMrzxlYtte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bag_clf.oob_decision_function_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYfR1sQjYLyy",
        "outputId": "0378515e-3eb2-4e27-c84a-a9099c343df7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44262295, 0.55737705],\n",
              "       [0.34554974, 0.65445026],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07692308, 0.92307692],\n",
              "       [0.33519553, 0.66480447],\n",
              "       [0.0049505 , 0.9950495 ],\n",
              "       [0.99444444, 0.00555556],\n",
              "       [0.97368421, 0.02631579],\n",
              "       [0.78362573, 0.21637427],\n",
              "       [0.01197605, 0.98802395],\n",
              "       [0.75409836, 0.24590164],\n",
              "       [0.86631016, 0.13368984],\n",
              "       [0.98514851, 0.01485149],\n",
              "       [0.06976744, 0.93023256],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98019802, 0.01980198],\n",
              "       [0.95108696, 0.04891304],\n",
              "       [1.        , 0.        ],\n",
              "       [0.02673797, 0.97326203],\n",
              "       [0.31746032, 0.68253968],\n",
              "       [0.90659341, 0.09340659],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97382199, 0.02617801],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.69512195, 0.30487805],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.16384181, 0.83615819],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.4375    , 0.5625    ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.18085106, 0.81914894],\n",
              "       [0.39583333, 0.60416667],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03592814, 0.96407186],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.97765363, 0.02234637],\n",
              "       [0.92      , 0.08      ],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.96153846, 0.03846154],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03333333, 0.96666667],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01136364, 0.98863636],\n",
              "       [1.        , 0.        ],\n",
              "       [0.77272727, 0.22727273],\n",
              "       [0.37560976, 0.62439024],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.67914439, 0.32085561],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.91712707, 0.08287293],\n",
              "       [1.        , 0.        ],\n",
              "       [0.58378378, 0.41621622],\n",
              "       [0.13812155, 0.86187845],\n",
              "       [0.67015707, 0.32984293],\n",
              "       [0.91836735, 0.08163265],\n",
              "       [0.        , 1.        ],\n",
              "       [0.14354067, 0.85645933],\n",
              "       [0.8839779 , 0.1160221 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.04191617, 0.95808383],\n",
              "       [0.04545455, 0.95454545],\n",
              "       [0.26857143, 0.73142857],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.82978723, 0.17021277],\n",
              "       [0.00574713, 0.99425287],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.20108696, 0.79891304],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.92432432, 0.07567568],\n",
              "       [0.78191489, 0.21808511],\n",
              "       [0.00478469, 0.99521531],\n",
              "       [1.        , 0.        ],\n",
              "       [0.22404372, 0.77595628],\n",
              "       [0.6741573 , 0.3258427 ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.04918033, 0.95081967],\n",
              "       [0.52513966, 0.47486034],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03333333, 0.96666667],\n",
              "       [1.        , 0.        ],\n",
              "       [0.27011494, 0.72988506],\n",
              "       [0.4787234 , 0.5212766 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.99468085, 0.00531915],\n",
              "       [0.34444444, 0.65555556],\n",
              "       [0.87700535, 0.12299465],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.81005587, 0.18994413],\n",
              "       [1.        , 0.        ],\n",
              "       [0.0106383 , 0.9893617 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00526316, 0.99473684],\n",
              "       [0.95833333, 0.04166667],\n",
              "       [0.99438202, 0.00561798],\n",
              "       [0.03428571, 0.96571429],\n",
              "       [0.26701571, 0.73298429],\n",
              "       [0.96067416, 0.03932584],\n",
              "       [0.23595506, 0.76404494],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.68508287, 0.31491713],\n",
              "       [0.39247312, 0.60752688],\n",
              "       [0.40526316, 0.59473684],\n",
              "       [0.85638298, 0.14361702],\n",
              "       [0.93333333, 0.06666667],\n",
              "       [0.07608696, 0.92391304],\n",
              "       [0.82828283, 0.17171717],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00995025, 0.99004975],\n",
              "       [0.98245614, 0.01754386],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02702703, 0.97297297],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96335079, 0.03664921],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.35483871, 0.64516129],\n",
              "       [0.30285714, 0.69714286],\n",
              "       [0.01020408, 0.98979592],\n",
              "       [0.        , 1.        ],\n",
              "       [0.26344086, 0.73655914],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99459459, 0.00540541],\n",
              "       [0.00568182, 0.99431818],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98378378, 0.01621622],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00613497, 0.99386503],\n",
              "       [0.66028708, 0.33971292],\n",
              "       [0.88757396, 0.11242604],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98314607, 0.01685393],\n",
              "       [0.99487179, 0.00512821],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.07731959, 0.92268041],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05813953, 0.94186047],\n",
              "       [0.00507614, 0.99492386],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02222222, 0.97777778],\n",
              "       [1.        , 0.        ],\n",
              "       [0.9281768 , 0.0718232 ],\n",
              "       [0.77717391, 0.22282609],\n",
              "       [0.53535354, 0.46464646],\n",
              "       [0.        , 1.        ],\n",
              "       [0.19886364, 0.80113636],\n",
              "       [1.        , 0.        ],\n",
              "       [0.94845361, 0.05154639],\n",
              "       [0.97647059, 0.02352941],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.42051282, 0.57948718],\n",
              "       [0.85142857, 0.14857143],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00510204, 0.99489796],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00507614, 0.99492386],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96354167, 0.03645833],\n",
              "       [0.        , 1.        ],\n",
              "       [0.27683616, 0.72316384],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99415205, 0.00584795],\n",
              "       [0.8       , 0.2       ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07853403, 0.92146597],\n",
              "       [1.        , 0.        ],\n",
              "       [0.02824859, 0.97175141],\n",
              "       [0.        , 1.        ],\n",
              "       [0.04761905, 0.95238095],\n",
              "       [1.        , 0.        ],\n",
              "       [0.82539683, 0.17460317],\n",
              "       [0.        , 1.        ],\n",
              "       [0.91719745, 0.08280255],\n",
              "       [0.99404762, 0.00595238],\n",
              "       [0.21195652, 0.78804348],\n",
              "       [0.25396825, 0.74603175],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.25698324, 0.74301676],\n",
              "       [0.96132597, 0.03867403],\n",
              "       [0.00571429, 0.99428571],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.41242938, 0.58757062],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.06285714, 0.93714286],\n",
              "       [0.05847953, 0.94152047],\n",
              "       [0.97826087, 0.02173913],\n",
              "       [0.02645503, 0.97354497],\n",
              "       [1.        , 0.        ],\n",
              "       [0.44270833, 0.55729167],\n",
              "       [0.13903743, 0.86096257],\n",
              "       [0.50802139, 0.49197861],\n",
              "       [0.58910891, 0.41089109],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.51648352, 0.48351648],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.22413793, 0.77586207],\n",
              "       [0.84831461, 0.15168539],\n",
              "       [0.03846154, 0.96153846],\n",
              "       [1.        , 0.        ],\n",
              "       [0.82539683, 0.17460317],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00571429, 0.99428571],\n",
              "       [0.11864407, 0.88135593],\n",
              "       [0.02185792, 0.97814208],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99487179, 0.00512821],\n",
              "       [0.92397661, 0.07602339],\n",
              "       [0.15882353, 0.84117647],\n",
              "       [0.96132597, 0.03867403],\n",
              "       [0.        , 1.        ],\n",
              "       [0.56565657, 0.43434343],\n",
              "       [0.08805031, 0.91194969],\n",
              "       [0.98857143, 0.01142857],\n",
              "       [0.82914573, 0.17085427],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.93023256, 0.06976744],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.31188119, 0.68811881],\n",
              "       [0.99456522, 0.00543478],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00549451, 0.99450549],\n",
              "       [0.89502762, 0.10497238],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.72192513, 0.27807487],\n",
              "       [0.96256684, 0.03743316],\n",
              "       [1.        , 0.        ],\n",
              "       [0.70558376, 0.29441624],\n",
              "       [0.48466258, 0.51533742],\n",
              "       [0.        , 1.        ],\n",
              "       [0.94339623, 0.05660377],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.85789474, 0.14210526],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.7345679 , 0.2654321 ],\n",
              "       [0.12315271, 0.87684729],\n",
              "       [0.49723757, 0.50276243],\n",
              "       [0.20689655, 0.79310345],\n",
              "       [0.        , 1.        ],\n",
              "       [0.86440678, 0.13559322],\n",
              "       [0.86503067, 0.13496933],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99425287, 0.00574713],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.01775148, 0.98224852],\n",
              "       [0.95336788, 0.04663212],\n",
              "       [0.96984925, 0.03015075],\n",
              "       [1.        , 0.        ],\n",
              "       [0.52150538, 0.47849462],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99029126, 0.00970874],\n",
              "       [0.02139037, 0.97860963],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97368421, 0.02631579],\n",
              "       [0.00537634, 0.99462366],\n",
              "       [0.06703911, 0.93296089],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00581395, 0.99418605],\n",
              "       [1.        , 0.        ],\n",
              "       [0.14361702, 0.85638298],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00578035, 0.99421965],\n",
              "       [0.        , 1.        ],\n",
              "       [0.43617021, 0.56382979],\n",
              "       [0.10404624, 0.89595376],\n",
              "       [0.25136612, 0.74863388],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99404762, 0.00595238],\n",
              "       [0.24468085, 0.75531915],\n",
              "       [0.9947644 , 0.0052356 ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96391753, 0.03608247],\n",
              "       [0.31460674, 0.68539326],\n",
              "       [0.98901099, 0.01098901],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98469388, 0.01530612],\n",
              "       [0.00552486, 0.99447514],\n",
              "       [0.05027933, 0.94972067],\n",
              "       [0.98958333, 0.01041667],\n",
              "       [1.        , 0.        ],\n",
              "       [0.04232804, 0.95767196],\n",
              "       [0.61538462, 0.38461538]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7.3 랜덤 패치와 랜덤 서브스페이스\n",
        "\n",
        "* `BaggingClassifier`는 특성 샘플링도 지원\n",
        "  * *max_features,bootstrap_features*\n",
        "  * **특성**에 대한 샘플링 : 각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련\n",
        "\n",
        "* **랜덤패치방식** | 훈련 특성과 샘플을 모두 샘플링하는 것\n",
        "\n",
        "* **랜덤서브스페이스방식** | 훈련 샘플을 **모두 사용**`bootstrap = False, max_samples = 1.0`하고 특성은 **샘플링**하는 것 `bootstrap_features = True, max_features < 1.0 `"
      ],
      "metadata": {
        "id": "i35o6c7iuw-W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## 7.4 랜덤 포레스트\n",
        "\n",
        "* 일반적으로 배깅 방법(또는 페이스팅)을 적용한 결정 트리의 앙상블\n",
        "  * *max_samples*를 훈련 세트의 크기로 지정"
      ],
      "metadata": {
        "id": "5w8YluR0v4iA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rnd_clf = RandomForestClassifier(n_estimators = 500, max_leaf_nodes = 16, n_jobs = -1)\n",
        "rnd_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "0RAggDA7w92O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#BaggingClassifier\n",
        "\n",
        "bag_clf = BaggingClassifier(\n",
        "    DecisionTreeClassifier(max_features = 'auto', max_leaf_nodes = 16),\n",
        "    n_estimators = 500, max_samples = 1.0, bootstrap = True, n_jobs = -1\n",
        ")"
      ],
      "metadata": {
        "id": "J2KpPD2-U7Jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 엑스트라 트리\n",
        "\n",
        ": 극단적으로 무작위한 트리의 랜덤 포레스트/ 편향이 늘어나지만 대신 분산을 낮춤"
      ],
      "metadata": {
        "id": "nQi0beAHY1G-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 특성 중요도\n",
        "\n",
        "* 사이킷런은 훈련이 끝난 뒤 특성마다 자동으로 이 점수를 계산하고 중요도의 전체 합이 1이 되도록 결괏값을 정규화함"
      ],
      "metadata": {
        "id": "_0slSnooZFAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators = 500, n_jobs = -1)\n",
        "rnd_clf.fit(iris['data'],iris['target'])\n",
        "for name, score in zip(iris['feature_names'], rnd_clf.feature_importances_) :\n",
        "  print(name,score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59hciMOrZECU",
        "outputId": "3d4729c1-71a7-433c-e554-0a7797d9d44c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sepal length (cm) 0.09691361057420006\n",
            "sepal width (cm) 0.02345681133972607\n",
            "petal length (cm) 0.4275133676147639\n",
            "petal width (cm) 0.45211621047131006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7.5 부스팅\n",
        "\n",
        ": **약한 학습기**를 여러 개 연결하여 강한 학습기를 만드는 앙상블 방법"
      ],
      "metadata": {
        "id": "X-c6DUH5ZvK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) 에이다부스트\n",
        "\n",
        "* 이전 예측기를 보완하는 새로운 예측기를 만드는 방법은 이전 모델이 **과소적합**했던 훈련 샘플의 가중치를 더 높이는 것\n",
        "* 에이다부스트 앙상블이 훈련 세트에 **과대적합**되면 추정기 수를 줄이거나 추정기의 규제를 더 강화하기"
      ],
      "metadata": {
        "id": "NeTq20nWZ7DT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada_clf = AdaBoostClassifier(\n",
        "    DeicisonTreeClassifier(max_depth = 1), n_estimators = 200,\n",
        "    algorithm = 'SAMME.R', learning_rate = 0.5\n",
        ")\n",
        "\n",
        "ada_clf.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "WSx8Ckf0b17i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) 그레이디언트 부스팅\n",
        "\n",
        "* 에이다부스트처럼 앙상블에 이전의 오차를 보정하도록 예측기를 순차적으로 추가하지만 반복마다 샘플의 가중치를 수정하는 대신 이전 에측기가 만든 **잔여 오차**에 새로운 예측기를 학습시킴\n",
        "\n",
        "* `learning_rate` 매개변수가 각 트리의 기여 정도를 조절함"
      ],
      "metadata": {
        "id": "ZRlgea1xcPP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth = 2)\n",
        "tree_reg1.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "iPeMefOXeHi0",
        "outputId": "c177fdaa-4017-4f8f-d08e-ad5ea55af805"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#첫 번째 예측기에서 생긴 잔여 오차에 두번쨰 DT 훈련\n",
        "\n",
        "y2 = y-tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth = 2)\n",
        "tree_reg2.fit(X,y2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "OTXuZ8EKeRWH",
        "outputId": "2268ce9f-619d-473b-d582-25673a7a6762"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#두 번째 예측기가 만든 잔여 오차에 세 번쨰 회귀모델 훈련\n",
        "\n",
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth = 2)\n",
        "tree_reg3.fit(X,y3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "vy_5HcAreb3M",
        "outputId": "6d88bf90-b508-4a7f-fc96-928c7628a10c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeRegressor(max_depth=2)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#새로운 샘플에 대한 예측을 만들기 위해 모든 트리의 예측 더하면 됨\n",
        "\n",
        "y_pred = sum(tree.predict(X) for tree in (tree_reg1, tree_reg2, tree_reg3))"
      ],
      "metadata": {
        "id": "eG93Id4-enXd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 3, learning_rate = 1.0)\n",
        "gbrt.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "D0tC6VUHe3sv",
        "outputId": "40c6458c-3fa9-496f-c0a5-a8a87a025d9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=1.0, max_depth=2, n_estimators=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 최적의 트리 수를 찾기 위해서는 조기 종료 기법을 사용할 수 있음 => `staged_predict()`\n",
        "\n",
        "* 훈련의 각 단계에서 앙상블에 의해 만들어진 예측기를 순회하는 반복자를 반환"
      ],
      "metadata": {
        "id": "5Acz22qnfbjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train,X_val,y_train,y_val = train_test_split(X,y)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth = 2, n_estimators = 120)\n",
        "gbrt.fit(X_train, y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val,y_pred)\n",
        "for y_pred in gbrt.staged_predict(X_val)]\n",
        "\n",
        "bst_n_estimators = np.argmin(errors) + 1\n",
        "\n",
        "gbrt_best = GradientBoostingRegressor(max_depth = 2, n_estimators = bst_n_estimators)\n",
        "gbrt_best.fit(X_train,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "yhxNUHdpfo98",
        "outputId": "b741957b-d339-443a-82aa-699379d2cf6a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(max_depth=2, n_estimators=117)"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(max_depth=2, n_estimators=117)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(max_depth=2, n_estimators=117)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 실제로 훈련을 중지하는 방법으로 조기 종료 구현\n",
        "\n",
        "`warm_start = True`로 설정하면 사이킷런이 fit() 메서드가 호출될 때 기존 트리를 유지하고 훈련을 추가할 수 있도록 해줌\n",
        "\n",
        "* 연속해서 다섯 번의 반복 동안 검증 오차가 향상되지 않으면 훈련을 멈춤"
      ],
      "metadata": {
        "id": "w7bZ-cJqgcUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbrt = GradientBoostingRegressor(max_depth = 2, warm_start = True)\n",
        "\n",
        "min_val_error = float('inf')\n",
        "error_going_up = 0\n",
        "\n",
        "for n_estimators in range(1,120) :\n",
        "  gbrt.n_estimators = n_estimators\n",
        "  gbrt.fit(X_train,y_train)\n",
        "  y_pred = gbrt.predict(X_val)\n",
        "  val_error = mean_squared_error(y_val, y_pred)\n",
        "  if val_error < min_val_error :\n",
        "    min_val_error = val_error\n",
        "    error_going_up = 0\n",
        "  else :\n",
        "    error_going_up += 1\n",
        "    if error_going_up == 5 :\n",
        "      break"
      ],
      "metadata": {
        "id": "Q5l1MKU2gqBe"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 각 트리가 훈련 될 때 사용할 훈련 샘플의 비율 지정 `subsample = 0.25`\n",
        "=> **확률적 그레이디언트 부스팅**\n"
      ],
      "metadata": {
        "id": "_czy7S0QhvKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (1) XGB"
      ],
      "metadata": {
        "id": "XcE9kUouh8UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "\n",
        "xgb_reg = xgboost.XGBRegressor()\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "id": "6iHMyX6-h9n-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_reg.fit(X_train,y_train,\n",
        "            eval_set = [(X_val, y_val)], early_stopping_rounds = 2)\n",
        "y_pred = xgb_reg.predict(X_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdcFLjFiiHmR",
        "outputId": "710cfac9-a798-4589-880c-eda495bc4b54"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:0.40507\n",
            "[1]\tvalidation_0-rmse:0.35347\n",
            "[2]\tvalidation_0-rmse:0.32152\n",
            "[3]\tvalidation_0-rmse:0.30545\n",
            "[4]\tvalidation_0-rmse:0.29699\n",
            "[5]\tvalidation_0-rmse:0.29607\n",
            "[6]\tvalidation_0-rmse:0.30157\n",
            "[7]\tvalidation_0-rmse:0.29921\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/xgboost/sklearn.py:835: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## 7.6 스태킹\n",
        "\n",
        "* 앙상블에 속한 모든 예측기의 예측을 취합하는 간단한 함수를 사용하는 대신 취합하는  모델을 훈련시킬 수 없나?!\n",
        "\n",
        "1. 훈련 세트를 두 개의 서브셋으로 나눔. 첫 번째 서브셋은 첫번재 레이어의 예측을 훈련시키기 위해 사용됨\n",
        "2. 첫 번째 레이어의 예측기를 사용해 두 번쨰 세트에 대한 예측을 만듦. 예측은 완전히 새로운 것\n",
        "3. 홀드 아웃 세트(두번쨰)의 각 샘플에 대해 세 개의 예측값이 있음. 타깃값은 그대로 쓰고 앞에서 예측한 값을 입력 특성으로 사용하는 새로운 훈련 세트를 만들 수 있음(3차원)\n",
        "4. 첫 번째 레이어의 예측을 가지고 타깃값을 예측하도록 학습"
      ],
      "metadata": {
        "id": "_zE4d7wiiT9O"
      }
    }
  ]
}